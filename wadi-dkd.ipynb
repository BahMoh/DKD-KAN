{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9720141,"sourceType":"datasetVersion","datasetId":5946920}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score, precision_score, recall_score, accuracy_score\nfrom collections import Counter\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport time, os, random, copy\nimport joblib\nimport math\nimport pickle as p\nimport seaborn as sns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The WADI dataset can be downloaded (or added on Kaggle) from this [Link](https://www.kaggle.com/datasets/giovannimonco/wadi-data)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Read the CSV, skipping the first row (which contains unwanted text or an extra header)\ndata_path_attack = \"/kaggle/input/wadi-data/WADI_attackdataLABLE.csv\"\nattack_csv = pd.read_csv(data_path_attack, header=1)\n\n# Strip all column names to remove leading/trailing whitespace\nattack_csv.columns = attack_csv.columns.str.strip()\n\n# Now you can safely set 'Row' as the index\ndf_attack = attack_csv.set_index('Row')\n\ndf_attack = df_attack.drop([\"Date\", \"Time\"], axis=1)\ndf_attack.rename(columns={\"Attack LABLE (1:No Attack, -1:Attack)\": \"target\"}, inplace=True)\n\nnum_nans = df_attack.isna().sum()\n\nfor feature in num_nans[num_nans>2].index:\n    df_attack.pop(feature)\n\ndf_attack = df_attack.iloc[0:-2]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_attack.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_attack = df_attack.pop(\"target\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_attack = label_attack.map({1: 0, -1: 1})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Counter(label_attack)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = df_attack\ny = label_attack\n\nprint(X.shape, y.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 1200","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SEED = 24\ntest_ratio = 0.2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def set_seed(seed_value):\n    \"\"\"Set seed for reproducibility.\"\"\"\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    torch.cuda.manual_seed(seed_value)\n    torch.cuda.manual_seed_all(seed_value)\n    # sklearn.random.seed(seed_value)\n    # sklearn.utils.check_random_state(seed_value)\n    joblib.parallel_backend('threading', n_jobs=1)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n# Set seed for reproducibility\nset_seed(SEED)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train , x_test , y_train , y_test = train_test_split(X, y, test_size=test_ratio, random_state=SEED, shuffle=True)\nx_train.shape, x_test.shape, y_train.shape, y_test.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(x_train)\n\nx_train_standardized = scaler.transform(x_train)\nx_test_standardized = scaler.transform(x_test)\n\nprint(np.mean(x_train_standardized), np.mean(x_test_standardized))\nprint(np.std(x_train_standardized), np.std(x_test_standardized))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\ndef dkd_loss(logits_student, logits_teacher, target, config):\n    alpha = config.beta\n    beta = config.gammar\n    temperature = config.temperature\n    gt_mask = _get_gt_mask(logits_student, target)\n    other_mask = _get_other_mask(logits_student, target)\n    pred_student = F.softmax(logits_student / temperature, dim=1)\n    pred_teacher = F.softmax(logits_teacher / temperature, dim=1)\n    pred_student = cat_mask(pred_student, gt_mask, other_mask)\n    pred_teacher = cat_mask(pred_teacher, gt_mask, other_mask)\n    log_pred_student = torch.log(pred_student)\n    tckd_loss = (\n        F.kl_div(log_pred_student, pred_teacher, reduction='sum')\n        * (temperature**2)\n        / target.shape[0]\n    )\n    pred_teacher_part2 = F.softmax(\n        logits_teacher / temperature - 1000.0 * gt_mask, dim=1\n    )\n    log_pred_student_part2 = F.log_softmax(\n        logits_student / temperature - 1000.0 * gt_mask, dim=1\n    )\n    nckd_loss = (\n        F.kl_div(log_pred_student_part2, pred_teacher_part2, reduction='sum')\n        * (temperature**2)\n        / target.shape[0]\n    )\n    return alpha * tckd_loss + beta * nckd_loss\n\ndef kd_loss(logits_student, logits_teacher, config):\n    temperature = config.temperature\n    log_pred_student = F.log_softmax(logits_student / temperature, dim=1)\n    pred_teacher = F.softmax(logits_teacher / temperature, dim=1)\n    loss_kd = F.kl_div(log_pred_student, pred_teacher, reduction=\"none\").sum(1).mean()\n    loss_kd *= temperature**2\n    return loss_kd\n\ndef _get_gt_mask(logits, target):\n    target = target.reshape(-1)\n    mask = torch.zeros_like(logits).scatter_(1, target.unsqueeze(1), 1).bool()\n    return mask\n\n\ndef _get_other_mask(logits, target):\n    target = target.reshape(-1)\n    mask = torch.ones_like(logits).scatter_(1, target.unsqueeze(1), 0).bool()\n    return mask\n\n\ndef cat_mask(t, mask1, mask2):\n    t1 = (t * mask1).sum(dim=1, keepdims=True)\n    t2 = (t * mask2).sum(1, keepdims=True)\n    rt = torch.cat([t1, t2], dim=1)\n    return rt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count parameters\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class KANLinear(torch.nn.Module):\n    def __init__(\n        self,\n        in_features,\n        out_features,\n        grid_size=5,\n        spline_order=3,\n        scale_noise=0.1,\n        scale_base=1.0,\n        scale_spline=1.0,\n        enable_standalone_scale_spline=True,\n        base_activation=torch.nn.SiLU,\n        grid_eps=0.02,\n        grid_range=[-1, 1],\n    ):\n        super(KANLinear, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.grid_size = grid_size\n        self.spline_order = spline_order\n\n        h = (grid_range[1] - grid_range[0]) / grid_size\n        grid = (\n            (\n                torch.arange(-spline_order, grid_size + spline_order + 1) * h\n                + grid_range[0]\n            )\n            .expand(in_features, -1)\n            .contiguous()\n        )\n        self.register_buffer(\"grid\", grid)\n\n        self.base_weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n        self.spline_weight = torch.nn.Parameter(\n            torch.Tensor(out_features, in_features, grid_size + spline_order)\n        )\n        if enable_standalone_scale_spline:\n            self.spline_scaler = torch.nn.Parameter(\n                torch.Tensor(out_features, in_features)\n            )\n\n        self.scale_noise = scale_noise\n        self.scale_base = scale_base\n        self.scale_spline = scale_spline\n        self.enable_standalone_scale_spline = enable_standalone_scale_spline\n        self.base_activation = base_activation()\n        self.grid_eps = grid_eps\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        torch.nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5) * self.scale_base)\n        with torch.no_grad():\n            noise = (\n                (\n                    torch.rand(self.grid_size + 1, self.in_features, self.out_features)\n                    - 1 / 2\n                )\n                * self.scale_noise\n                / self.grid_size\n            )\n            self.spline_weight.data.copy_(\n                (self.scale_spline if not self.enable_standalone_scale_spline else 1.0)\n                * self.curve2coeff(\n                    self.grid.T[self.spline_order : -self.spline_order],\n                    noise,\n                )\n            )\n            if self.enable_standalone_scale_spline:\n                # torch.nn.init.constant_(self.spline_scaler, self.scale_spline)\n                torch.nn.init.kaiming_uniform_(self.spline_scaler, a=math.sqrt(5) * self.scale_spline)\n\n    def b_splines(self, x: torch.Tensor):\n        \"\"\"\n        Compute the B-spline bases for the given input tensor.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n\n        Returns:\n            torch.Tensor: B-spline bases tensor of shape (batch_size, in_features, grid_size + spline_order).\n        \"\"\"\n        assert x.dim() == 2 and x.size(1) == self.in_features\n\n        grid: torch.Tensor = (\n            self.grid\n        )  # (in_features, grid_size + 2 * spline_order + 1)\n        x = x.unsqueeze(-1)\n        bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n        for k in range(1, self.spline_order + 1):\n            bases = (\n                (x - grid[:, : -(k + 1)])\n                / (grid[:, k:-1] - grid[:, : -(k + 1)])\n                * bases[:, :, :-1]\n            ) + (\n                (grid[:, k + 1 :] - x)\n                / (grid[:, k + 1 :] - grid[:, 1:(-k)])\n                * bases[:, :, 1:]\n            )\n\n        assert bases.size() == (\n            x.size(0),\n            self.in_features,\n            self.grid_size + self.spline_order,\n        )\n        return bases.contiguous()\n\n    def curve2coeff(self, x: torch.Tensor, y: torch.Tensor):\n        \"\"\"\n        Compute the coefficients of the curve that interpolates the given points.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n            y (torch.Tensor): Output tensor of shape (batch_size, in_features, out_features).\n\n        Returns:\n            torch.Tensor: Coefficients tensor of shape (out_features, in_features, grid_size + spline_order).\n        \"\"\"\n        assert x.dim() == 2 and x.size(1) == self.in_features\n        assert y.size() == (x.size(0), self.in_features, self.out_features)\n\n        A = self.b_splines(x).transpose(\n            0, 1\n        )  # (in_features, batch_size, grid_size + spline_order)\n        B = y.transpose(0, 1)  # (in_features, batch_size, out_features)\n        solution = torch.linalg.lstsq(\n            A, B\n        ).solution  # (in_features, grid_size + spline_order, out_features)\n        result = solution.permute(\n            2, 0, 1\n        )  # (out_features, in_features, grid_size + spline_order)\n\n        assert result.size() == (\n            self.out_features,\n            self.in_features,\n            self.grid_size + self.spline_order,\n        )\n        return result.contiguous()\n\n    @property\n    def scaled_spline_weight(self):\n        return self.spline_weight * (\n            self.spline_scaler.unsqueeze(-1)\n            if self.enable_standalone_scale_spline\n            else 1.0\n        )\n\n    def forward(self, x: torch.Tensor):\n        assert x.size(-1) == self.in_features\n        original_shape = x.shape\n        x = x.view(-1, self.in_features)\n\n        base_output = F.linear(self.base_activation(x), self.base_weight)\n        spline_output = F.linear(\n            self.b_splines(x).view(x.size(0), -1),\n            self.scaled_spline_weight.view(self.out_features, -1),\n        )\n        output = base_output + spline_output\n        \n        output = output.view(*original_shape[:-1], self.out_features)\n        return output\n\n    @torch.no_grad()\n    def update_grid(self, x: torch.Tensor, margin=0.01):\n        assert x.dim() == 2 and x.size(1) == self.in_features\n        batch = x.size(0)\n\n        splines = self.b_splines(x)  # (batch, in, coeff)\n        splines = splines.permute(1, 0, 2)  # (in, batch, coeff)\n        orig_coeff = self.scaled_spline_weight  # (out, in, coeff)\n        orig_coeff = orig_coeff.permute(1, 2, 0)  # (in, coeff, out)\n        unreduced_spline_output = torch.bmm(splines, orig_coeff)  # (in, batch, out)\n        unreduced_spline_output = unreduced_spline_output.permute(\n            1, 0, 2\n        )  # (batch, in, out)\n\n        # sort each channel individually to collect data distribution\n        x_sorted = torch.sort(x, dim=0)[0]\n        grid_adaptive = x_sorted[\n            torch.linspace(\n                0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device\n            )\n        ]\n\n        uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.grid_size\n        grid_uniform = (\n            torch.arange(\n                self.grid_size + 1, dtype=torch.float32, device=x.device\n            ).unsqueeze(1)\n            * uniform_step\n            + x_sorted[0]\n            - margin\n        )\n\n        grid = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n        grid = torch.concatenate(\n            [\n                grid[:1]\n                - uniform_step\n                * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1),\n                grid,\n                grid[-1:]\n                + uniform_step\n                * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),\n            ],\n            dim=0,\n        )\n\n        self.grid.copy_(grid.T)\n        self.spline_weight.data.copy_(self.curve2coeff(x, unreduced_spline_output))\n\n    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n        \"\"\"\n        Compute the regularization loss.\n\n        This is a dumb simulation of the original L1 regularization as stated in the\n        paper, since the original one requires computing absolutes and entropy from the\n        expanded (batch, in_features, out_features) intermediate tensor, which is hidden\n        behind the F.linear function if we want an memory efficient implementation.\n\n        The L1 regularization is now computed as mean absolute value of the spline\n        weights. The authors implementation also includes this term in addition to the\n        sample-based regularization.\n        \"\"\"\n        l1_fake = self.spline_weight.abs().mean(-1)\n        regularization_loss_activation = l1_fake.sum()\n        p = l1_fake / regularization_loss_activation\n        regularization_loss_entropy = -torch.sum(p * p.log())\n        return (\n            regularize_activation * regularization_loss_activation\n            + regularize_entropy * regularization_loss_entropy\n        )\n\n\nclass KAN(torch.nn.Module):\n    def __init__(\n        self,\n        layers_hidden,\n        grid_size=5,\n        spline_order=3,\n        scale_noise=0.1,\n        scale_base=1.0,\n        scale_spline=1.0,\n        base_activation=torch.nn.SiLU,\n        grid_eps=0.02,\n        grid_range=[-1, 1],\n    ):\n        super(KAN, self).__init__()\n        self.grid_size = grid_size\n        self.spline_order = spline_order\n\n        self.layers = torch.nn.ModuleList()\n        for in_features, out_features in zip(layers_hidden, layers_hidden[1:]):\n            self.layers.append(\n                KANLinear(\n                    in_features,\n                    out_features,\n                    grid_size=grid_size,\n                    spline_order=spline_order,\n                    scale_noise=scale_noise,\n                    scale_base=scale_base,\n                    scale_spline=scale_spline,\n                    base_activation=base_activation,\n                    grid_eps=grid_eps,\n                    grid_range=grid_range,\n                )\n            )\n\n    def forward(self, x: torch.Tensor, update_grid=False):\n        for layer in self.layers:\n            if update_grid:\n                layer.update_grid(x)\n            x = layer(x)\n        return x\n\n    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n        return sum(\n            layer.regularization_loss(regularize_activation, regularize_entropy)\n            for layer in self.layers\n        )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Teacher Model\n","metadata":{}},{"cell_type":"code","source":"# Spline order\ns_o = 6\n# Grid size\ng_s = 20","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class KAN_model(nn.Module):\n\n    def __init__(self):\n        super(KAN_model, self).__init__()\n        self.KAN1 = KAN([123, 30], grid_size=g_s, spline_order=s_o, grid_range=[-4, 4])\n        self.projection = KAN([30, 2], grid_size=g_s, spline_order=s_o, grid_range=[-1, 1])\n\n    def forward(self, x):\n\n\n        x = x.view(x.shape[0], 1,-1)\n        out = self.KAN1(x)\n        out = self.projection(out)\n        out_f = out.view(x.shape[0], out.size(1) * out.size(2))\n\n\n        return out_f","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"teacher_model = KAN_model()\nprint(f\"Total parameters of KAN teacher_model: {count_parameters(teacher_model)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Student Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass MLP_model(nn.Module):\n    def __init__(self):\n        super(MLP_model, self).__init__()\n        \n        self.fc1 = nn.Linear(123, 20)\n        self.fc2 = nn.Linear(20, 2)\n        \n    def forward(self, x):\n        x = x.view(x.shape[0], -1)  # Flatten input\n        out = torch.relu(self.fc1(x))\n        out = self.fc2(out)\n        return out\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"student_model = MLP_model()\nprint(f\"Total parameters of MLP student_model: {count_parameters(student_model)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def Create_Dataloader(train_data, val_data, train_label, val_label, batch_size = 8):\n\n    # train, valid, test split\n    X_train, X_valid, y_train, y_valid = train_data, val_data, train_label, val_label\n\n    trainX = np.array(X_train)\n    y_train = np.array(y_train)\n    validX = np.array(X_valid)\n    y_valid = np.array(y_valid)\n\n    # reshaping data\n    X_train1 = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n    X_valid1 = np.reshape(validX, (validX.shape[0],validX.shape[1],1))\n\n    # Create the DataLoader for our data\n    X_train1 = torch.tensor(X_train1)\n    X_valid1 = torch.tensor(X_valid1)\n\n    y_train = torch.tensor(y_train).type(torch.LongTensor)\n    y_valid = torch.tensor(y_valid).type(torch.LongTensor)\n\n\n    train_data = TensorDataset(X_train1, y_train)\n    valid_data = TensorDataset(X_valid1, y_valid)\n\n    train_sampler = RandomSampler(train_data)\n    valid_sampler = RandomSampler(valid_data)\n\n    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n    valid_dataloader = DataLoader(valid_data, batch_size=batch_size)\n\n    return train_dataloader, valid_dataloader","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_confusion_matrix(y_true, y_pred, positive, negative):\n\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n\n    TP, FP, FN, TN = 0, 0, 0, 0\n\n    for i in range(len(y_pred)):\n\n        if y_pred[i] == positive:\n            if y_true[i] == positive:\n                TP += 1  # True Positive\n            else:\n                FP += 1  # False Positive\n\n        elif y_pred[i] == negative:\n            if y_true[i] == negative:\n                TN += 1  # True Negative\n            else:\n                FN += 1  # False Negative\n\n    return np.array([[TP, FN], [FP, TN]])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def classification_metrics(conf_matrix):\n\n    TP = conf_matrix[0,0]\n    FN = conf_matrix[0,1]\n    FP = conf_matrix[1,0]\n    TN = conf_matrix[1,1]\n\n    acc = (TP + TN) / (TP + FN + FP + TN)\n    precision = TP / (TP + FP)\n    recall = TP / (TP + FN)\n    f1 = 2 * (precision * recall) / (precision + recall)\n    return acc, f1, precision, recall\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train teacher model","metadata":{}},{"cell_type":"code","source":"def train_teacher(model, optimizer, ep, train_dataloader_final, val_dataloader_final, evaluation=False):\n    \"\"\"Train the final model.\n    \"\"\"\n\n    # Start training loop\n    print(\"Start training...\\n\")\n    tr_ep_loss = []\n    tr_ep_acc = []\n    tr_ep_f1 = []\n    tr_ep_precision = []\n    tr_ep_recall = []\n\n    val_ep_loss = []\n    val_ep_acc = []\n    val_ep_f1 = []\n    val_ep_precision = []\n    val_ep_recall = []\n\n    best_val_recall = 0\n    best_val_f1 = 0\n\n    loss_fn = nn.CrossEntropyLoss()\n\n    for e in range(1, ep + 1):\n        # =======================================\n        #               Training\n        # =======================================\n        # Measure the elapsed time of each epoch\n        t0_epoch, t0_batch = time.time(), time.time()\n\n        # Reset tracking variables at the beginning of each epoch\n        total_loss, batch_loss, batch_counts = 0, 0, 0\n\n        # Put the model into the training mode\n        model.train()\n\n        # For each batch of training data...\n        loss_sublist = np.array([])\n        acc_sublist = np.array([])\n        f1_sublist = np.array([])\n        precision_sublist = np.array([])\n        recall_sublist = np.array([])\n\n        y_actual = np.array([])\n        y_pred = np.array([])\n\n        for batch, (x, y) in enumerate(train_dataloader_final):\n#             x.to(device)\n#             y.to(device)\n            batch_counts +=1\n            optimizer.zero_grad()\n\n            # positive pair, with encoding\n            z = model(x.to(device).float())\n            #y_true.append(y.squeeze(1).numpy())\n\n            # calculate loss\n            loss = loss_fn(z, y.to(device).squeeze())\n            loss.backward()\n\n            preds = torch.exp(z.cpu().data)/torch.sum(torch.exp(z.cpu().data))\n\n            y_actual = np.append(y_actual, y.view(-1).cpu().numpy().astype('int'))\n            y_pred = np.append(y_pred, np.argmax(preds.cpu().numpy() ,axis=1).astype('int'))\n            loss_sublist = np.append(loss_sublist, loss.cpu().data)\n\n            optimizer.step()\n\n            # Zero out any previously calculated gradients\n            model.zero_grad()\n\n            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        conf_matrix = calculate_confusion_matrix(y_actual, y_pred,1,0)\n        acc, f1, precision, recall = classification_metrics(conf_matrix)\n\n        # Reset batch tracking variables\n        batch_loss, batch_counts = 0, 0\n        t0_batch = time.time()\n        #scheduler.step()\n\n        # Calculate the average loss over the entire training data\n        avg_train_loss = np.mean(loss_sublist)\n        tr_ep_loss.append(avg_train_loss)\n        tr_ep_acc.append(acc)\n        tr_ep_f1.append(f1)\n        tr_ep_precision.append(precision)\n        tr_ep_recall.append(recall)\n        # =======================================\n        #               Evaluation\n        # =======================================\n        if evaluation == True:\n            # After the completion of each training epoch, measure the model's performance\n            # on our validation set.\n            val_loss, val_accuracy, val_f1, val_precision, val_recall = evaluate(model, val_dataloader_final)\n\n\n            if val_f1>best_val_f1:\n                best_model_f1=copy.deepcopy(model)\n                model_name_location = f\"/kaggle/working/best_teacher_model.pt\"\n                torch.save(best_model_f1.state_dict(), model_name_location)\n                best_val_f1 = val_f1\n                print(\"This is the best f1 score!\")\n\n            val_ep_loss.append(val_loss)\n            val_ep_acc.append(val_accuracy)\n            val_ep_f1.append(val_f1)\n            val_ep_precision.append(val_precision)\n            val_ep_recall.append(val_recall)\n\n            time_elapsed = time.time() - t0_epoch\n\n            # Print the header of the result table\n            print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Train Accuracy':^12} | {'Train F1-score':^12} |{'Train Precision':^12} |{'Train Recall':^12} | {'Val Loss':^12} | {'Val Accuuracy':^12} | {'Val F1-score':^12}|{'Val Precision':^12}|{'Val Recall':^12}| {'Elapsed':^9}\")\n            print(\"-\"*81)\n            print(f\"{e:^7} | {avg_train_loss:^12.6f} | {acc:^14.6} | {f1:^14.6} | {precision:^14.6} |{recall:^14.6} |{val_loss:^12.6f} | {val_accuracy:^14.6f} | {val_f1:^14.6f}|{val_precision:^14.6f}|{val_recall:^14.6f}| {time_elapsed:^9.2f}\")\n            print(\"-\"*81)\n        print(\"\\n\")\n\n    # plot train and valid loss\n    plt.plot(list(range(len(val_ep_loss))), val_ep_loss, label = \"Validation Loss\")\n    plt.plot(list(range(len(tr_ep_loss))), tr_ep_loss, label = \"Training Loss\")\n    plt.title('Loss of Classification')\n    plt.xlabel('Number of epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.savefig('/kaggle/working/head_loss.png')\n    plt.show()\n\n    # plot train and valid accuracy\n    plt.plot(list(range(len(val_ep_acc))), val_ep_acc, label = \"Validation Accuracy\")\n    plt.plot(list(range(len(tr_ep_acc))), tr_ep_acc, label = \"Training Accuracy\")\n    plt.title('Accuracy of Classification')\n    plt.xlabel('Number of epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.savefig('/kaggle/working/head_acc.png')\n\n    plt.show()\n\n    plt.plot(list(range(len(val_ep_precision))), val_ep_precision, label = \"Validation Precision\")\n    plt.plot(list(range(len(tr_ep_precision))), tr_ep_precision, label = \"Training Precision\")\n    plt.title('Precision of Classification')\n    plt.xlabel('Number of epochs')\n    plt.ylabel('Precision')\n    plt.legend()\n    plt.savefig('/kaggle/working/head_precision.png')\n\n    plt.show()\n\n    plt.plot(list(range(len(val_ep_f1))), val_ep_f1, label = \"Validation F1 Score\")\n    plt.plot(list(range(len(tr_ep_f1))), tr_ep_f1, label = \"Training F1 Score\")\n    plt.title('F1-Score of Classification')\n    plt.xlabel('Number of epochs')\n    plt.ylabel('F1-Score')\n    plt.legend()\n    plt.savefig('/kaggle/working/head_f1.png')\n\n    plt.show()\n\n    plt.plot(list(range(len(val_ep_recall))), val_ep_recall, label = \"Validation Recall\")\n    plt.plot(list(range(len(tr_ep_recall))), tr_ep_recall, label = \"Training Recall\")\n    plt.title('Recall of Classification')\n    plt.xlabel('Number of epochs')\n    plt.ylabel('Recall')\n    plt.legend()\n    plt.savefig('/kaggle/working/head_recall.png')\n\n    plt.show()\n    \n    print(\"Teacher Training complete!\")\n    print(\"Best f1-score: best_val_f1\")\n    return best_val_recall, best_val_f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate(model, val_dataloader):\n    \"\"\"After the completion of each training epoch, measure the model's performance\n    on our validation set.\n    \"\"\"\n    val_ep_loss = []\n    val_ep_acc = []\n    val_ep_f1=[]\n    val_ep_precision=[]\n    val_ep_recall=[]\n\n    model.eval()\n    y_actual = np.array([])\n    y_pred = np.array([])\n\n    loss_sublist = np.array([])\n    acc_sublist = np.array([])\n    f1_sublist = np.array([])\n    precision_sublist = np.array([])\n    recall_sublist = np.array([])\n\n    loss_fn = nn.CrossEntropyLoss()\n    # loss_fn = nn.BCELoss()\n\n    with torch.no_grad():\n        for x, y in val_dataloader:\n\n            z = model(x.to(device).float())\n            #y_true.append(y.squeeze(1).numpy())\n            # Compute the average loss over the validation set.\n            val_loss = loss_fn(z,y.to(device).squeeze())\n\n            # model's prediction\n            preds = torch.exp(z.cpu().data)/torch.sum(torch.exp(z.cpu().data))\n            loss_sublist = np.append(loss_sublist, val_loss.cpu().data)\n\n            y_actual = np.append(y_actual, y.cpu().view(-1).numpy().astype('int'))\n            y_pred = np.append(y_pred, np.argmax(preds.cpu().numpy(), axis=1).astype('int'))\n\n        conf_matrix = calculate_confusion_matrix(y_actual, y_pred,1,0)\n        acc, f1, precision, recall = classification_metrics(conf_matrix)\n    return np.mean(loss_sublist), acc, f1, precision, recall","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = \"cuda:0\"\n# device = \"cpu\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epoch = 100\nteacher_model.to(device)\noptimizer = torch.optim.AdamW(teacher_model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataloader, val_dataloader = Create_Dataloader(x_train_standardized, x_test_standardized, y_train , y_test, batch_size)\n_, best_teacher_f1 = train_teacher(teacher_model, optimizer, epoch, train_dataloader, val_dataloader, evaluation=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_digits\n\n# Load dataset\nmodel = KAN_model()\nmodel.load_state_dict(torch.load('/kaggle/working/best_teacher_model.pt'))\nall_extracted_features = []\nall_true_labels = []\n\nglobal_index = 0 \n\nwith torch.no_grad():\n    for x, y in val_dataloader:\n        x = x.to(\"cpu\").float()\n        extracted_features = model(x)\n\n        for i in range(x.size(0)):  # Loop through the batch\n            if global_index % 10 == 0:  # Keep only every 10th sample\n                all_extracted_features.append(extracted_features[i].cpu().numpy())\n                all_true_labels.append(y[i].item())\n            global_index += 1\n            \nX = np.array(all_extracted_features)\ny = np.array(all_true_labels)\n\n# Initialize and fit t-SNE\ny = y.reshape(-1)\n# Initialize and fit t-SNE\ntsne = TSNE(n_components=2, random_state=42)\nX_tsne = tsne.fit_transform(X)\n\n# Plot the results\nplt.figure(figsize=(8, 6))\nlabels = np.unique(y)\n# Loop over the labels to plot each class separately\nfor label in labels:\n    plt.scatter(X_tsne[y == label, 0], X_tsne[y == label, 1], cmap='jet', label=f'Class {label}', s=50, alpha=0.7)\n\nplt.legend()\n# plt.colorbar(scatter)\nplt.title('t-SNE Visualization SWaT, After Pre-training')\nplt.xlabel('t-SNE Component 1')\nplt.ylabel('t-SNE Component 2')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nwith open(\"wadi_teacher.p\", \"wb\") as file:\n    dict_tSNE = {}\n    dict_tSNE[\"tSNE\"]=X_tsne\n    dict_tSNE[\"labels\"]=all_true_labels\n    p.dump(dict_tSNE, file)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_confusion_matrix_vis(model, test_dataloader):\n    \"\"\"Calculates the confusion matrix for the model on the test data.\"\"\"\n    model.eval()\n    all_predicted_labels = []\n    all_true_labels = []\n\n    with torch.no_grad():\n        for x, y in test_dataloader:\n            z = model(x.to(\"cpu\").float())\n            predicted_labels = torch.argmax(torch.exp(z.cpu().data) / torch.sum(torch.exp(z.cpu().data)), dim=1)\n\n            all_predicted_labels.extend(predicted_labels.cpu().numpy().tolist())\n            all_true_labels.extend(y.cpu().numpy().tolist())\n\n    conf_matrix = confusion_matrix(all_true_labels, all_predicted_labels)\n    \n    classes = [\"Normal\", \"Attack\"]\n\n    # Plot confusion matrix\n    plt.figure(figsize=(10, 10))\n    sns.set(font_scale=1.2)  # Adjust font size\n    sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues',\n                xticklabels=classes, yticklabels=classes,\n                cbar_kws={'label': 'Number of samples'})\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n    return conf_matrix","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# We test mafualda data on the IMS trained data\nbest_model_path = \"/kaggle/working/best_teacher_model.pt\"\n\n# load best model trained on IMS\nbest_model = KAN_model()\n# best_model, _ = init_model(best_model,8)\nbest_model.load_state_dict(torch.load(best_model_path))\n\ncalculate_confusion_matrix_vis(best_model, val_dataloader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train Student model single","metadata":{}},{"cell_type":"code","source":"def train_student(model, optimizer, ep, train_dataloader_final, val_dataloader_final, evaluation=False):\n    \"\"\"Train the final model.\n    \"\"\"\n\n    # Start training loop\n    print(\"Start training...\\n\")\n    tr_ep_loss = []\n    tr_ep_acc = []\n    tr_ep_f1 = []\n    tr_ep_precision = []\n    tr_ep_recall = []\n\n    val_ep_loss = []\n    val_ep_acc = []\n    val_ep_f1 = []\n    val_ep_precision = []\n    val_ep_recall = []\n\n    best_val_recall = 0\n    best_val_f1 = 0\n\n    loss_fn = nn.CrossEntropyLoss()\n\n    for e in range(1, ep + 1):\n        # =======================================\n        #               Training\n        # =======================================\n        # Measure the elapsed time of each epoch\n        t0_epoch, t0_batch = time.time(), time.time()\n\n        # Reset tracking variables at the beginning of each epoch\n        total_loss, batch_loss, batch_counts = 0, 0, 0\n\n        # Put the model into the training mode\n        model.train()\n\n        # For each batch of training data...\n        loss_sublist = np.array([])\n        acc_sublist = np.array([])\n        f1_sublist = np.array([])\n        precision_sublist = np.array([])\n        recall_sublist = np.array([])\n\n        y_actual = np.array([])\n        y_pred = np.array([])\n\n        for batch, (x, y) in enumerate(train_dataloader_final):\n#             x.to(device)\n#             y.to(device)\n            batch_counts +=1\n            optimizer.zero_grad()\n\n            # positive pair, with encoding\n            z = model(x.to(device).float())\n            #y_true.append(y.squeeze(1).numpy())\n\n            # calculate loss\n            loss = loss_fn(z, y.to(device).squeeze())\n            loss.backward()\n\n            preds = torch.exp(z.cpu().data)/torch.sum(torch.exp(z.cpu().data))\n\n            y_actual = np.append(y_actual, y.view(-1).cpu().numpy().astype('int'))\n            y_pred = np.append(y_pred, np.argmax(preds.cpu().numpy() ,axis=1).astype('int'))\n            loss_sublist = np.append(loss_sublist, loss.cpu().data)\n\n            optimizer.step()\n\n            # Zero out any previously calculated gradients\n            model.zero_grad()\n\n            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        conf_matrix = calculate_confusion_matrix(y_actual, y_pred,1,0)\n        acc, f1, precision, recall = classification_metrics(conf_matrix)\n\n        # Reset batch tracking variables\n        batch_loss, batch_counts = 0, 0\n        t0_batch = time.time()\n\n        # Calculate the average loss over the entire training data\n        avg_train_loss = np.mean(loss_sublist)\n        tr_ep_loss.append(avg_train_loss)\n\n        tr_ep_acc.append(acc)\n        tr_ep_f1.append(f1)\n        tr_ep_precision.append(precision)\n        tr_ep_recall.append(recall)\n        # =======================================\n        #               Evaluation\n        # =======================================\n        if evaluation == True:\n            # After the completion of each training epoch, measure the model's performance\n            # on our validation set.\n            val_loss, val_accuracy, val_f1, val_precision, val_recall = evaluate(model, val_dataloader_final)\n\n            if val_f1>best_val_f1:\n                best_model_f1=copy.deepcopy(model)\n                model_name_location = f\"/kaggle/working/best_student_model.pt\"\n                torch.save(best_model_f1.state_dict(), model_name_location)\n                best_val_f1 = val_f1\n                print(\"This is the best f1 score!\")\n\n            val_ep_loss.append(val_loss)\n            val_ep_acc.append(val_accuracy)\n            val_ep_f1.append(val_f1)\n            val_ep_precision.append(val_precision)\n            val_ep_recall.append(val_recall)\n\n            time_elapsed = time.time() - t0_epoch\n\n            # Print the header of the result table\n            print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Train Accuracy':^12} | {'Train F1-score':^12} |{'Train Precision':^12} |{'Train Recall':^12} | {'Val Loss':^12} | {'Val Accuuracy':^12} | {'Val F1-score':^12}|{'Val Precision':^12}|{'Val Recall':^12}| {'Elapsed':^9}\")\n            print(\"-\"*81)\n            print(f\"{e:^7} | {avg_train_loss:^12.6f} | {acc:^14.6} | {f1:^14.6} | {precision:^14.6} |{recall:^14.6} |{val_loss:^12.6f} | {val_accuracy:^14.6f} | {val_f1:^14.6f}|{val_precision:^14.6f}|{val_recall:^14.6f}| {time_elapsed:^9.2f}\")\n            print(\"-\"*81)\n        print(\"\\n\")\n\n    # plot train and valid loss\n    plt.plot(list(range(len(val_ep_loss))), val_ep_loss, label = \"Validation Loss\")\n    plt.plot(list(range(len(tr_ep_loss))), tr_ep_loss, label = \"Training Loss\")\n    plt.title('Loss of Classification')\n    plt.xlabel('Number of epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.savefig('/kaggle/working/head_loss.png')\n    plt.show()\n\n    # plot train and valid accuracy\n    plt.plot(list(range(len(val_ep_acc))), val_ep_acc, label = \"Validation Accuracy\")\n    plt.plot(list(range(len(tr_ep_acc))), tr_ep_acc, label = \"Training Accuracy\")\n    plt.title('Accuracy of Classification')\n    plt.xlabel('Number of epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.savefig('/kaggle/working/head_acc.png')\n\n    plt.show()\n\n    plt.plot(list(range(len(val_ep_precision))), val_ep_precision, label = \"Validation Precision\")\n    plt.plot(list(range(len(tr_ep_precision))), tr_ep_precision, label = \"Training Precision\")\n    plt.title('Precision of Classification')\n    plt.xlabel('Number of epochs')\n    plt.ylabel('Precision')\n    plt.legend()\n    plt.savefig('/kaggle/working/head_precision.png')\n\n    plt.show()\n\n    plt.plot(list(range(len(val_ep_f1))), val_ep_f1, label = \"Validation F1 Score\")\n    plt.plot(list(range(len(tr_ep_f1))), tr_ep_f1, label = \"Training F1 Score\")\n    plt.title('F1-Score of Classification')\n    plt.xlabel('Number of epochs')\n    plt.ylabel('F1-Score')\n    plt.legend()\n    plt.savefig('/kaggle/working/head_f1.png')\n\n    plt.show()\n\n    plt.plot(list(range(len(val_ep_recall))), val_ep_recall, label = \"Validation Recall\")\n    plt.plot(list(range(len(tr_ep_recall))), tr_ep_recall, label = \"Training Recall\")\n    plt.title('Recall of Classification')\n    plt.xlabel('Number of epochs')\n    plt.ylabel('Recall')\n    plt.legend()\n    plt.savefig('/kaggle/working/head_recall.png')\n\n    plt.show()\n    \n    print(\"Student Training complete!\")\n    print(f\"Best f1-score: {best_val_f1}\")\n    return best_val_recall, best_val_f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epoch = 100\nstudent_model.to(device)\noptimizer = torch.optim.AdamW(student_model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"student_model.to(device)\n_, best_student_f1 = train_student(student_model, optimizer, epoch, train_dataloader, val_dataloader, evaluation=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_digits\n\n# Load dataset\nmodel = MLP_model()\nmodel.load_state_dict(torch.load('/kaggle/working/best_student_model.pt'))\nall_extracted_features = []\nall_true_labels = []\n\nglobal_index = 0 \n\nwith torch.no_grad():\n    for x, y in val_dataloader:\n        x = x.to(\"cpu\").float()\n        extracted_features = model(x)\n\n        for i in range(x.size(0)):  # Loop through the batch\n            if global_index % 10 == 0:  # Keep only every 10th sample\n                all_extracted_features.append(extracted_features[i].cpu().numpy())\n                all_true_labels.append(y[i].item())\n            global_index += 1\n            \nX = np.array(all_extracted_features)\ny = np.array(all_true_labels)\n\n# Initialize and fit t-SNE\ny = y.reshape(-1)\n# Initialize and fit t-SNE\ntsne = TSNE(n_components=2, random_state=SEED)\nX_tsne = tsne.fit_transform(X)\n\n# Plot the results\nplt.figure(figsize=(8, 6))\nlabels = np.unique(y)\n# Loop over the labels to plot each class separately\nfor label in labels:\n    plt.scatter(X_tsne[y == label, 0], X_tsne[y == label, 1], cmap='jet', label=f'Class {label}', s=50, alpha=0.7)\n\nplt.legend()\n# plt.colorbar(scatter)\nplt.title('t-SNE Visualization SWaT, After Pre-training')\nplt.xlabel('t-SNE Component 1')\nplt.ylabel('t-SNE Component 2')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"wadi_student.p\", \"wb\") as file:\n    dict_tSNE = {}\n    dict_tSNE[\"tSNE\"]=X_tsne\n    dict_tSNE[\"labels\"]=all_true_labels\n    p.dump(dict_tSNE, file)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# We test mafualda data on the IMS trained data\nbest_model_path = \"/kaggle/working/best_student_model.pt\"\n\n# load best model trained on IMS\nbest_model = MLP_model()\n# best_model, _ = init_model(best_model,8)\nbest_model.load_state_dict(torch.load(best_model_path))\n\ncalculate_confusion_matrix_vis(best_model, val_dataloader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# DKDL train function","metadata":{}},{"cell_type":"code","source":"def train_student_DKDL(student_model, teacher_model, optimizer, ep, train_dataloader_final, val_dataloader_final, evaluation=False):\n    \"\"\"Train the final model.\n    \"\"\"\n    student_model.train()\n    teacher_model.eval()\n    \n    # Start training loop\n    print(\"Start training...\\n\")\n    tr_ep_loss = []\n    tr_ep_acc = []\n    tr_ep_f1 = []\n    tr_ep_precision = []\n    tr_ep_recall = []\n\n    val_ep_loss = []\n    val_ep_acc = []\n    val_ep_f1 = []\n    val_ep_precision = []\n    val_ep_recall = []\n\n    best_val_recall = 0\n    best_val_f1 = 0\n\n    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n\n    for e in range(1, ep + 1):\n        # =======================================\n        #               Training\n        # =======================================\n        # Measure the elapsed time of each epoch\n        t0_epoch, t0_batch = time.time(), time.time()\n\n        # Reset tracking variables at the beginning of each epoch\n        total_loss, batch_loss, batch_counts = 0, 0, 0\n\n        # For each batch of training data...\n        loss_sublist = np.array([])\n        acc_sublist = np.array([])\n        f1_sublist = np.array([])\n        precision_sublist = np.array([])\n        recall_sublist = np.array([])\n\n        y_actual = np.array([])\n        y_pred = np.array([])\n\n        for batch, (x, y) in enumerate(train_dataloader_final):\n            x = x.to(device)\n            y = y.to(device)\n            batch_counts +=1\n            optimizer.zero_grad()\n\n            # positive pair, with encoding\n            y_s = student_model(x.float())\n            y_t = teacher_model(x.float())\n\n            # calculate loss\n            hard_loss = loss_fn(y_t, y.to(device).squeeze())\n            soft_loss = dkd_loss(y_s, y_t, y, config)\n            soft_loss = min(e / config.warmup, 1.0) * soft_loss # DKD\n            loss = (1-config.alpha)*hard_loss + config.alpha*soft_loss\n            \n            loss.backward()\n\n            preds = torch.exp(y_s.cpu().data)/torch.sum(torch.exp(y_s.cpu().data))\n\n            y_actual = np.append(y_actual, y.view(-1).cpu().numpy().astype('int'))\n            y_pred = np.append(y_pred, np.argmax(preds.cpu().numpy() ,axis=1).astype('int'))\n            loss_sublist = np.append(loss_sublist, loss.cpu().data)\n\n            optimizer.step()\n\n            # Zero out any previously calculated gradients\n            student_model.zero_grad()\n\n            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n            torch.nn.utils.clip_grad_norm_(student_model.parameters(), 1.0)\n\n        conf_matrix = calculate_confusion_matrix(y_actual, y_pred,1,0)\n        acc, f1, precision, recall = classification_metrics(conf_matrix)\n\n        # Reset batch tracking variables\n        batch_loss, batch_counts = 0, 0\n        t0_batch = time.time()\n\n\n        # Calculate the average loss over the entire training data\n        avg_train_loss = np.mean(loss_sublist)\n        tr_ep_loss.append(avg_train_loss)\n        tr_ep_acc.append(acc)\n        tr_ep_f1.append(f1)\n        tr_ep_precision.append(precision)\n        tr_ep_recall.append(recall)\n        # =======================================\n        #               Evaluation\n        # =======================================\n        if evaluation == True:\n            # After the completion of each training epoch, measure the model's performance\n            # on our validation set.\n            val_loss, val_accuracy, val_f1, val_precision, val_recall = evaluate(student_model, val_dataloader_final)\n\n            if val_f1>best_val_f1:\n                best_model_f1=copy.deepcopy(student_model)\n                model_name_location = f\"/kaggle/working/best_student_model_DKDL.pt\"\n                torch.save(best_model_f1.state_dict(), model_name_location)\n                best_val_f1 = val_f1\n                print(\"This is the best f1 score!\")\n\n            val_ep_loss.append(val_loss)\n            val_ep_acc.append(val_accuracy)\n            val_ep_f1.append(val_f1)\n            val_ep_precision.append(val_precision)\n            val_ep_recall.append(val_recall)\n\n            time_elapsed = time.time() - t0_epoch\n\n            # Print the header of the result table\n            print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Train Accuracy':^12} | {'Train F1-score':^12} |{'Train Precision':^12} |{'Train Recall':^12} | {'Val Loss':^12} | {'Val Accuuracy':^12} | {'Val F1-score':^12}|{'Val Precision':^12}|{'Val Recall':^12}| {'Elapsed':^9}\")\n            print(\"-\"*81)\n            print(f\"{e:^7} | {avg_train_loss:^12.6f} | {acc:^14.6} | {f1:^14.6} | {precision:^14.6} |{recall:^14.6} |{val_loss:^12.6f} | {val_accuracy:^14.6f} | {val_f1:^14.6f}|{val_precision:^14.6f}|{val_recall:^14.6f}| {time_elapsed:^9.2f}\")\n            print(\"-\"*81)\n        print(\"\\n\")\n\n    # plot train and valid loss\n    plt.plot(list(range(len(val_ep_loss))), val_ep_loss, label = \"Validation Loss\")\n    plt.plot(list(range(len(tr_ep_loss))), tr_ep_loss, label = \"Training Loss\")\n    plt.title('Loss of Classification')\n    plt.xlabel('Number of epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.savefig('/kaggle/working/head_loss.png')\n    plt.show()\n\n    # plot train and valid accuracy\n    plt.plot(list(range(len(val_ep_acc))), val_ep_acc, label = \"Validation Accuracy\")\n    plt.plot(list(range(len(tr_ep_acc))), tr_ep_acc, label = \"Training Accuracy\")\n    plt.title('Accuracy of Classification')\n    plt.xlabel('Number of epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.savefig('/kaggle/working/head_acc.png')\n\n    plt.show()\n\n    plt.plot(list(range(len(val_ep_precision))), val_ep_precision, label = \"Validation Precision\")\n    plt.plot(list(range(len(tr_ep_precision))), tr_ep_precision, label = \"Training Precision\")\n    plt.title('Precision of Classification')\n    plt.xlabel('Number of epochs')\n    plt.ylabel('Precision')\n    plt.legend()\n    plt.savefig('/kaggle/working/head_precision.png')\n\n    plt.show()\n\n    plt.plot(list(range(len(val_ep_f1))), val_ep_f1, label = \"Validation F1 Score\")\n    plt.plot(list(range(len(tr_ep_f1))), tr_ep_f1, label = \"Training F1 Score\")\n    plt.title('F1-Score of Classification')\n    plt.xlabel('Number of epochs')\n    plt.ylabel('F1-Score')\n    plt.legend()\n    plt.savefig('/kaggle/working/head_f1.png')\n\n    plt.show()\n\n    plt.plot(list(range(len(val_ep_recall))), val_ep_recall, label = \"Validation Recall\")\n    plt.plot(list(range(len(tr_ep_recall))), tr_ep_recall, label = \"Training Recall\")\n    plt.title('Recall of Classification')\n    plt.xlabel('Number of epochs')\n    plt.ylabel('Recall')\n    plt.legend()\n    plt.savefig('/kaggle/working/head_recall.png')\n\n    plt.show()\n    \n    print(\"Student Training complete!\")\n    print(f\"Best f1-score: {best_val_f1}\")\n    return best_val_recall, best_val_f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class configTrainDKD:\n    alpha = 0.2 \n    beta = 5\n    gammar = 1\n    warmup = 5\n    temperature = 2.5\n\nconfig = configTrainDKD()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Draw conf mat for\nbest_model_teacher_model = \"/kaggle/working/best_teacher_model.pt\"\n\n# load best model trained\nbest_teacher_model = KAN_model()\nbest_teacher_model.load_state_dict(torch.load(best_model_teacher_model))\nbest_teacher_model.to(device)\nbest_teacher_model = best_teacher_model.float()\n\nstudent_model = MLP_model()\nstudent_model.to(device)\nstudent_model= student_model.float()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(student_model.parameters(), lr=0.0004, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epoch=400\ntrain_student_DKDL(student_model, teacher_model, optimizer, epoch, train_dataloader, val_dataloader, evaluation=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_digits\n\n# Load dataset\nmodel = MLP_model()\nmodel.load_state_dict(torch.load('/kaggle/working/best_student_model_DKDL.pt'))\nall_extracted_features = []\nall_true_labels = []\n\nglobal_index = 0 \n\nwith torch.no_grad():\n    for x, y in val_dataloader:\n        x = x.to(\"cpu\").float()\n        extracted_features = model(x)\n\n        for i in range(x.size(0)):  # Loop through the batch\n            if global_index % 10 == 0:  # Keep only every 10th sample\n                all_extracted_features.append(extracted_features[i].cpu().numpy())\n                all_true_labels.append(y[i].item())\n            global_index += 1\n            \nX = np.array(all_extracted_features)\ny = np.array(all_true_labels)\n\n# Initialize and fit t-SNE\ny = y.reshape(-1)\n# Initialize and fit t-SNE\ntsne = TSNE(n_components=2, random_state=SEED)\nX_tsne = tsne.fit_transform(X)\n\n# Plot the results\nplt.figure(figsize=(8, 6))\nlabels = np.unique(y)\n# Loop over the labels to plot each class separately\nfor label in labels:\n    plt.scatter(X_tsne[y == label, 0], X_tsne[y == label, 1], cmap='jet', label=f'Class {label}', s=50, alpha=0.7)\n\nplt.legend()\n# plt.colorbar(scatter)\nplt.title('t-SNE Visualization SWaT, After Pre-training')\nplt.xlabel('t-SNE Component 1')\nplt.ylabel('t-SNE Component 2')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"wadi_student_DKD.p\", \"wb\") as file:\n    dict_tSNE = {}\n    dict_tSNE[\"tSNE\"]=X_tsne\n    dict_tSNE[\"labels\"]=all_true_labels\n    p.dump(dict_tSNE, file)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# We test mafualda data on the IMS trained data\nbest_model_path = \"/kaggle/working/best_student_model_DKDL.pt\"\n\n# load best model trained on IMS\nbest_model = MLP_model()\n# best_model, _ = init_model(best_model,8)\nbest_model.load_state_dict(torch.load(best_model_path))\n\ncalculate_confusion_matrix_vis(best_model, val_dataloader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# t-SNE Plots\n","metadata":{}},{"cell_type":"markdown","source":"## Student model","metadata":{}},{"cell_type":"code","source":"with open(\"/kaggle/input/dkd-cyber-tsne-dataset/wadi_student.p\", \"rb\") as file:\n    con = p.load( file)\n\nlabels_gp = con[\"labels\"]\ntsne_gp= con[\"tSNE\"]\ny_gp = np.array(labels_gp)\ny_gp = y_gp.reshape(-1)\nlabels_un = np.unique(y_gp)\nplt.figure(figsize=(10,10))\nfor label in labels_un:\n    plt.scatter(tsne_gp[y_gp == label, 0], tsne_gp[y_gp == label, 1], cmap='jet', label=label_dict.get(label), s=50, alpha=0.9)\n\nplt.legend(framealpha=0.2, fontsize=13)\n# plt.colorbar(scatter)\nplt.title('WADI Dataset t-SNE Visualization, Student Model',fontsize=20)\nplt.xlabel('t-SNE Component 1',fontsize=15)\nplt.ylabel('t-SNE Component 2',fontsize=15)\nplt.savefig(\"wadi_student_tsne.eps\", dpi=300)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Teacher model","metadata":{}},{"cell_type":"code","source":"with open(\"/kaggle/input/dkd-cyber-tsne-dataset/wadi_teacher.p\", \"rb\") as file:\n    con = p.load( file)\n\nlabels_gp = con[\"labels\"]\ntsne_gp= con[\"tSNE\"]\ny_gp = np.array(labels_gp)\ny_gp = y_gp.reshape(-1)\nlabels_un = np.unique(y_gp)\nplt.figure(figsize=(10,10))\nfor label in labels_un:\n    plt.scatter(tsne_gp[y_gp == label, 0], tsne_gp[y_gp == label, 1], cmap='jet', label=label_dict.get(label), s=50, alpha=0.9)\n\nplt.legend(framealpha=0.2, fontsize=13)\n# plt.colorbar(scatter)\nplt.title('WADI Dataset t-SNE Visualization, Teacher Model',fontsize=20)\nplt.xlabel('t-SNE Component 1',fontsize=15)\nplt.ylabel('t-SNE Component 2',fontsize=15)\nplt.savefig(\"wadi_teacher_tsne.eps\", dpi=300)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## DKD-student model","metadata":{}},{"cell_type":"code","source":"with open(\"/kaggle/input/dkd-cyber-tsne-dataset/wadi_student_DKD.p\", \"rb\") as file:\n    con = p.load( file)\n\nlabels_gp = con[\"labels\"]\ntsne_gp= con[\"tSNE\"]\ny_gp = np.array(labels_gp)\ny_gp = y_gp.reshape(-1)\nlabels_un = np.unique(y_gp)\nplt.figure(figsize=(10,10))\nfor label in labels_un:\n    plt.scatter(tsne_gp[y_gp == label, 0], tsne_gp[y_gp == label, 1], cmap='jet', label=label_dict.get(label), s=50, alpha=0.9)\n\nplt.legend(framealpha=0.2, fontsize=13)\n# plt.colorbar(scatter)\nplt.title('WADI Dataset t-SNE Visualization, DKD-Student Model',fontsize=20)\nplt.xlabel('t-SNE Component 1',fontsize=15)\nplt.ylabel('t-SNE Component 2',fontsize=15)\nplt.savefig(\"wadi_dkd_student_tsne.eps\", dpi=300)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}